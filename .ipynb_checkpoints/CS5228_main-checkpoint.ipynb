{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major definition\n",
    "\n",
    "\"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" and \"Product Related Duration\" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The \"Bounce Rate\", \"Exit Rate\" and \"Page Value\" features represent the metrics measured by \"Google Analytics\" for each page in the e-commerce site. The value of \"Bounce Rate\" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server during that session.\n",
    "\n",
    "The value of \"Exit Rate\" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. \n",
    "\n",
    "The \"Page Value\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction.\n",
    "\n",
    "The \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and very date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. \n",
    "\n",
    "The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gradient boosting\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import ast\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA: columnar missing vals, distribution and some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    '''\n",
    "    display of missing information per column\n",
    "    '''\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "def plot_feature_distribution(df1, df2, label1, label2, features):\n",
    "    '''\n",
    "    numerical feature ditribution comparator for binary labelled segments\n",
    "    '''\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(3,3,figsize=(10,10))\n",
    "\n",
    "    for feature in features:\n",
    "        try:\n",
    "            i += 1\n",
    "            plt.subplot(3,3,i)\n",
    "            sns.distplot(df1[feature], hist=False,label=label1)\n",
    "            sns.distplot(df2[feature], hist=False,label=label2)\n",
    "            plt.xlabel(feature, fontsize=9)\n",
    "            locs, labels = plt.xticks()\n",
    "            plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
    "            plt.tick_params(axis='y', which='major', labelsize=6)\n",
    "        except:\n",
    "            continue\n",
    "    plt.show();\n",
    "    \n",
    "def count_ctgy_spread(df,ctgy_cols):\n",
    "    '''\n",
    "    count in each categorical column,\n",
    "    how many variety they have\n",
    "    returns the suggested methods to process columns, using config\n",
    "    '''\n",
    "    res = {}\n",
    "    advice = {}\n",
    "    for col in ctgy_cols:\n",
    "        val = df[col].value_counts().reset_index().shape[0]\n",
    "        if val <= 6:\n",
    "            advice[col] = 'one_hot'\n",
    "        elif val > 6 and val <= 10:\n",
    "            advice[col] = 'mid_level'\n",
    "        else:\n",
    "            advice[col] = 'encoding'\n",
    "        \n",
    "        res[col] = val\n",
    "    print('column:number of unique records')\n",
    "    return res,advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent</th>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0.113544201135442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Types</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Administrative Administrative_Duration      Informational  \\\n",
       "Total                   14                      14                 14   \n",
       "Percent  0.113544201135442       0.113544201135442  0.113544201135442   \n",
       "Types              float64                 float64            float64   \n",
       "\n",
       "        Informational_Duration     ProductRelated ProductRelated_Duration  \\\n",
       "Total                       14                 14                      14   \n",
       "Percent      0.113544201135442  0.113544201135442       0.113544201135442   \n",
       "Types                  float64            float64                 float64   \n",
       "\n",
       "               BounceRates          ExitRates PageValues SpecialDay   Month  \\\n",
       "Total                   14                 14          0          0       0   \n",
       "Percent  0.113544201135442  0.113544201135442          0          0       0   \n",
       "Types              float64            float64    float64     object  object   \n",
       "\n",
       "        OperatingSystems Browser  Region TrafficType VisitorType Weekend  \\\n",
       "Total                  0       0       0           0           0       0   \n",
       "Percent                0       0       0           0           0       0   \n",
       "Types             object  object  object      object      object    bool   \n",
       "\n",
       "        Revenue  \n",
       "Total         0  \n",
       "Percent       0  \n",
       "Types     int64  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting point, read in raw data\n",
    "df = pd.read_csv('online_shoppers_intention.csv')\n",
    "\n",
    "# categorical feature coersive conversion\n",
    "df['SpecialDay'] = df['SpecialDay'].astype('O')\n",
    "df['OperatingSystems'] = df['OperatingSystems'].astype('O')\n",
    "df['Browser'] = df['Browser'].astype('O')\n",
    "df['Region'] = df['Region'].astype('O')\n",
    "df['TrafficType'] = df['TrafficType'].astype('O')\n",
    "df['Revenue'] = df['Revenue'].astype(int)\n",
    "\n",
    "# convenient vars for columns\n",
    "feature_cols = df.columns.tolist()\n",
    "feature_cols.remove('Revenue')\n",
    "feature_obj_cols = df.select_dtypes('O').columns.tolist()\n",
    "feature_num_cols = [x for x in feature_cols if x not in feature_obj_cols]\n",
    "\n",
    "#show columnar missing values conditions\n",
    "missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillna on the numerical columns, using mean\n",
    "for col in df.select_dtypes(exclude='O').columns.tolist():\n",
    "    df[col].fillna(df[col].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build benchmark model, off the shelf LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(df,target_col):\n",
    "    '''\n",
    "    benchmark model, using simple off shelf models\n",
    "    we use LR off shelf as benchmark model\n",
    "    '''\n",
    "    \n",
    "    #fillna on the numerical columns, using mean\n",
    "    for col in df.select_dtypes(exclude='O').columns.tolist():\n",
    "        df[col].fillna(df[col].mean(),inplace=True)\n",
    "        \n",
    "    all_cols = df.columns.tolist()\n",
    "    all_cols.remove(target_col)\n",
    "    \n",
    "    X = pd.get_dummies(df[all_cols])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    #incurred a bit data leakage here due to get dummies, but it's ok due to this is a benchmark\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    model_names = ['LR'] \n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    #using default hyperparameter settings\n",
    "    lr_clf = LogisticRegression()\n",
    "\n",
    "    clf_list = [lr_clf]\n",
    "    clf_dict = dict(zip(model_names,clf_list))\n",
    "\n",
    "    for model in model_names:\n",
    "        clf = clf_dict[model]\n",
    "        #fit df\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        f1.append(round(f1_score(y_test, y_pred, average='weighted')*100,2))\n",
    "        acc.append(round(accuracy_score(y_test, y_pred)*100,2))\n",
    "\n",
    "    accuracy_record = pd.DataFrame({'Model': model_names, 'acc': acc})\n",
    "    accuracy_record.set_index('Model', inplace=True)\n",
    "    accuracy_record.loc['avg'] = accuracy_record.mean()\n",
    "\n",
    "    F1_record = pd.DataFrame({'Model': model_names, 'f1': f1})\n",
    "    F1_record.set_index('Model', inplace=True)\n",
    "    F1_record.loc['avg'] = F1_record.mean()\n",
    "\n",
    "    print(accuracy_record)\n",
    "    print('\\n')\n",
    "    print(F1_record);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      acc\n",
      "Model                    \n",
      "LR     88.159999999999997\n",
      "avg    88.159999999999997\n",
      "\n",
      "\n",
      "                       f1\n",
      "Model                    \n",
      "LR     86.739999999999995\n",
      "avg    86.739999999999995\n"
     ]
    }
   ],
   "source": [
    "ac = benchmark_model(df,target_col='Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "The \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and very date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:number of unique records\n"
     ]
    }
   ],
   "source": [
    "cols_variety, advice = count_ctgy_spread(df,df.select_dtypes(include=('O')).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "def decayed_tte(x):\n",
    "    '''\n",
    "    time to event\n",
    "    x input, rescaled output\n",
    "    '''\n",
    "    #if x is small, means not impactful, if x=1, then it's very close to special day\n",
    "    return exp(x-1)\n",
    "\n",
    "def get_likelihood_feature(df,feature,target):\n",
    "    '''\n",
    "    get a factual information for feature\n",
    "    conversion probability using singel column\n",
    "    '''\n",
    "    non_rev = train[train.Revenue==0].Month.value_counts().reset_index().rename(columns={'index':'month','Month':'count_non_rev'})\n",
    "    rev = train[train.Revenue==1].Month.value_counts().reset_index().rename(columns={'index':'month','Month':'count_rev'})\n",
    "    counts_month = pd.merge(non_rev,rev,on='month',how='inner')\n",
    "    counts_month['conversion_prob'] = counts_month['count_rev']/counts_month['count_non_rev']\n",
    "    mth = counts_month['month'].tolist()\n",
    "    prob = counts_month['conversion_prob'].tolist()\n",
    "    mth_prob = dict(zip(mth,prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mth_conv_prob'] = train['Month'].apply(lambda x:mth_prob[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['special_day_scaled'] = train['SpecialDay'].apply(lambda x:decayed_tte(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns='special_day_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SpecialDay': 'one_hot',\n",
       " 'Month': 'mid_level',\n",
       " 'OperatingSystems': 'mid_level',\n",
       " 'Browser': 'encoding',\n",
       " 'Region': 'mid_level',\n",
       " 'TrafficType': 'encoding',\n",
       " 'VisitorType': 'one_hot'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrf, xgb can't deal with cat features, need to transform to numerical\\nlightgbm and CatBoost, can input directly categorical feature。\\nFor lgbm: need to label encoding to find optimal split, better than 1-hot encoding.\\n\\n* For ordinal features (have latent orders), can use label encoding\\n* No order information, a few categories (<4), can use 1-hot\\n* Target encoding (mean/liklihood/impact encoding), can use non-ordinal, >4 categories\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "'''\n",
    "rf, xgb can't deal with cat features, need to transform to numerical\n",
    "lightgbm and CatBoost, can input directly categorical feature。\n",
    "For lgbm: need to label encoding to find optimal split, better than 1-hot encoding.\n",
    "\n",
    "* For ordinal features (have latent orders), can use label encoding\n",
    "* No order information, a few categories (<4), can use 1-hot\n",
    "* Target encoding (mean/liklihood/impact encoding), can use non-ordinal, >4 categories\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "normed_df = df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for col in feature_num_cols:\n",
    "    scaled_col = scaler.fit_transform(normed_df[col].values.reshape((-1,1)))\n",
    "    normed_df[col] = scaled_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
