{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gradient boosting\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('online_shoppers_intention.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "1. EDA and data exploration\n",
    "2. Preparation work\n",
    "3. Feature Engineering, multiple sets of features\n",
    "4. Training pipeline, with params tuning\n",
    "5. Test set performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars for columns\n",
    "feature_cols = df.columns.tolist()\n",
    "feature_cols.remove('Revenue')\n",
    "feature_obj_cols = df.select_dtypes('O').columns.tolist()\n",
    "feature_num_cols = [x for x in feature_cols if x not in feature_obj_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After replacing missing values: \n",
      "Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in feature_num_cols:\n",
    "    df[col].fillna(df[col].mean(),inplace=True)\n",
    "\n",
    "print('\\nAfter replacing missing values: ')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "normed_df = df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for col in feature_num_cols:\n",
    "    scaled_col = scaler.fit_transform(normed_df[col].values.reshape((-1,1)))\n",
    "    normed_df[col] = scaled_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df = pd.get_dummies(normed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12330, 28) (12330,)\n"
     ]
    }
   ],
   "source": [
    "# pima1 split\n",
    "x1 = normed_df.drop(columns='Revenue')\n",
    "y1 = normed_df['Revenue']\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size = 0.25, random_state=0)\n",
    "print(x1.shape, y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "search_space = {\"RF\": {'n_estimators': [25,100,300],\n",
    "                        'criterion': ['gini', 'entropy'],\n",
    "                        'bootstrap': [True, False]},\n",
    "                    \"GBM\": {'n_estimators': [25,100,300],\n",
    "                        'max_depth': [3,5,8],\n",
    "                        'learning_rate': [0.01,0.05,0.2],\n",
    "                        'loss': ['deviance', 'exponential']}}\n",
    "\n",
    "def params_tuning(clf_dict,classifier_tag,search_space):\n",
    "    '''\n",
    "    input classifier_tag to tune, with targetted search space\n",
    "    tags include RF, GBM\n",
    "    '''\n",
    "    #unpack search space, and classifier, according to tag\n",
    "    grid_param = search_space[classifier_tag]\n",
    "    classifier = clf_dict[classifier_tag]\n",
    "    \n",
    "    grid_search_obj = GridSearchCV(estimator=classifier, param_grid=grid_param, scoring='accuracy', cv=10,n_jobs=-1)\n",
    "    #fitting the training set of pima2 (train2)\n",
    "    grid_search_obj.fit(x_train1, y_train1)\n",
    "    \n",
    "    best_parameters = grid_search_obj.best_params_\n",
    "    best_accuracy = grid_search_obj.best_score_\n",
    "    \n",
    "    print('Classifier: '+classifier_tag)\n",
    "    print('best params found:',best_parameters)\n",
    "    print('with training accuracy:',best_accuracy)\n",
    "        \n",
    "    #fit pima2\n",
    "    y_pred1 = grid_search_obj.predict(x_test1)\n",
    "    \n",
    "    pima2_f1_best = round(f1_score(y_test1, y_pred1, average='weighted')*100,2)\n",
    "    pima2_acc_best = round(accuracy_score(y_test1, y_pred1)*100,2)\n",
    "    \n",
    "    print('best accuracy (test set):', pima2_acc_best)\n",
    "    print('best f1_Score (test set):', pima2_f1_best)\n",
    "    \n",
    "    #print out confusion matrix on testing set\n",
    "    conf_matrix = confusion_matrix(y_test1, y_pred1)\n",
    "    print('Confusion matrix on test set:')\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    return grid_search_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pima1_acc  acc_mean\n",
      "Model                     \n",
      "KNN       86.730    86.730\n",
      "LR        87.190    87.190\n",
      "DT        85.760    85.760\n",
      "RF        88.740    88.740\n",
      "GBM       89.070    89.070\n",
      "avg       87.498    87.498\n",
      "\n",
      "\n",
      "       pima1_f1  F1_mean\n",
      "Model                   \n",
      "KNN       85.18    85.18\n",
      "LR        85.35    85.35\n",
      "DT        85.64    85.64\n",
      "RF        87.98    87.98\n",
      "GBM       88.55    88.55\n",
      "avg       86.54    86.54\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbors, Logistic regression, Decision trees, Random forest, Gradient boosting machine\n",
    "model_names = ['KNN', 'LR', 'DT', 'RF', 'GBM'] \n",
    "pima1_acc = []\n",
    "pima2_acc = []\n",
    "pima1_f1 = []\n",
    "pima2_f1 = []\n",
    "\n",
    "# --- Your code here ---\n",
    "#using default hyperparameter settings\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "clf_list = [knn_clf,lr_clf,dt_clf,rf_clf,gbm_clf]\n",
    "clf_dict = dict(zip(model_names,clf_list))\n",
    "\n",
    "for model in model_names:\n",
    "    #looping through each model, in default setting\n",
    "    clf = clf_dict[model]\n",
    "    \n",
    "    #fit pima1\n",
    "    clf.fit(x_train1, y_train1)\n",
    "    y_pred1 = clf.predict(x_test1)\n",
    "    pima1_f1.append(round(f1_score(y_test1, y_pred1, average='weighted')*100,2))\n",
    "    pima1_acc.append(round(accuracy_score(y_test1, y_pred1)*100,2))\n",
    "    \n",
    "\n",
    "accuracy_record = pd.DataFrame({'Model': model_names, 'pima1_acc': pima1_acc})\n",
    "accuracy_record['acc_mean'] = accuracy_record.mean(axis=1).round(2)\n",
    "accuracy_record.set_index('Model', inplace=True)\n",
    "accuracy_record.loc['avg'] = accuracy_record.mean()\n",
    "\n",
    "F1_record = pd.DataFrame({'Model': model_names, 'pima1_f1': pima1_f1})\n",
    "F1_record['F1_mean'] = F1_record.mean(axis=1).round(2)\n",
    "F1_record.set_index('Model', inplace=True)\n",
    "F1_record.loc['avg'] = F1_record.mean()\n",
    "\n",
    "print(accuracy_record)\n",
    "print('\\n')\n",
    "print(F1_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'LR', 'DT', 'RF', 'GBM'] \n",
    "pima1_acc = []\n",
    "pima2_acc = []\n",
    "pima1_f1 = []\n",
    "pima2_f1 = []\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "clf_list = [knn_clf,lr_clf,dt_clf,rf_clf,gbm_clf]\n",
    "clf_dict = dict(zip(model_names,clf_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: GBM\n",
      "best params found: {'learning_rate': 0.05, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 100}\n",
      "with training accuracy: 0.9097016497016497\n",
      "best accuracy (test set): 89.07\n",
      "best f1_Score (test set): 88.57\n",
      "Confusion matrix on test set:\n",
      "[[2443  116]\n",
      " [ 221  303]]\n"
     ]
    }
   ],
   "source": [
    "GBM_tuned_clf = params_tuning(clf_dict,'GBM',search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RF\n",
      "best params found: {'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 300}\n",
      "with training accuracy: 0.9063484263484263\n",
      "best accuracy (test set): 89.36\n",
      "best f1_Score (test set): 88.78\n",
      "Confusion matrix on test set:\n",
      "[[2456  103]\n",
      " [ 225  299]]\n"
     ]
    }
   ],
   "source": [
    "RF_tuned_clf = params_tuning(clf_dict,'RF',search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
